---
title: "Machine Learning - Conceitos Aprendizagem de Máquinas"
author: "João Gustavo Rogel"
output:
  html_document:
    df_print: paged
---

### Exercícios Conceituais
#### 1
Aprendizagem de máquina consiste em criar um algoritmo capaz de traçar relações entre variáveis com o
intuito de gerar saídas baseadas em tais relações.

#### 2
Classificação de emails como spam ou não, predição de séries econômicas, identificação de imagens.

#### 3
A aprendizagem supervisionada é utilizada quando se tem um conjunto de dados já rotulados e deseja-se
encontrar rótulos para dados desconhecidos. Já na aprendizagem não supervisionada o conjunto de dados
para treino não possui nenuhm tipo de rótulo conhecido.

#### 4
São dados que já possuem um rótulo associado a ele, por exemplo, quando já se sabe que um é email é
spam.

#### 5
É a principal parte do aprendizado de máquina, constituído de um algoritmo de aprendizagem em um conjunto
de funções hipóteses.

#### 6
Poderia ser utilizado um algortimo de classificação.

#### 7
Na aprendizagem online o modelo também é treinado quando o mesmo já está em produção, o que não acontece
na aprendizagem offline.

#### 8
Os hiperpârametros são os dados que controlam o treinamento dos parâmetros do modelo.

#### 10
Muito provavelmente o modelo sofreu um overfitting com os dados de treinamento. Algumas coisas podem
ser feitas como, mudar taxas de aprendizados de treinamento, selecionar melhor os dados de treinamento,
escolher novas featurese para o modelo.


### Exercícios de Revisão - Probabilidade/Estatística
#### 1
A população consiste em todo o conjunto de dados, já a amostra é um subconjunto da população.

#### 2
A função PDF descreve a probabilidade relativa de uma variável aleatória tomada um valor. A função CDF é
a soma ou integral de uma função PDF.


### Exercícios de Múltipla Escolha
```{r echo=FALSE}
library(DT)

res_x <- data.frame("Q1" =  c("A"),
                    "Q2" =  c("C"),
                    "Q3" =  c("B"),
                    "Q4" =  c("D"),
                    "Q5" =  c("A"),
                    "Q6" =  c("C"),
                    "Q7" =  c("A"),
                    "Q8" =  c("B"),
                    "Q9" =  c("B"),
                    "Q10" = c("D")
                    )

datatable(res_x, rownames = FALSE)
```

### Exercícios Computacionais

Carregando bibliotecas
```{r message=FALSE, warning=FALSE}
library(xts)
library(maps)
library(dplyr)
library(moments)
library(mapdata)
library(leaflet)
library(ggplot2)
library(quantmod)
```




### Exercício Computacional - 1
```{r warning=FALSE}
# 1
df <- data.frame("id" = c(1, 2, 3, 4, 5),
                 "empresa" = c("A", "B", "C", "D", "E"),
                 "indices" = c(500.3, 530.2, 630.5, 400.2, 940.2),
                 "datas" = c("2020-03-05", "2020-04-21", "2020-12-10", "2020-10-15", "2020-09-20"))

# 2
str(df)

# 3
df_filtrado <- df %>% select(c("empresa", "indices"))

# 4
array_ele <- df[c(1, 3), c(2, 4)]

# 5
setores <- c("IT", "adm", "executivo", "RH", "O&M")
df_setor <- df
df_setor$setor <- setores

# 6
df_novo <- data.frame(
  id = c (6:10),
  empresa = c("F","F","G","K","L"),
  indices = c(1200.3,230.4,100.5,905.40,1100.50),
  datas = as.Date(c("2020-09-10", "2020-07-08", "2020-10-15", "2020-06-07","2020-02-22")))

df_bind <- rbind(df,df_novo)
```


### Exercício Computacional - 2
```{r warning=FALSE}
media <- 10
dp <- 5
r <- rnorm(1000, media, dp)

# 1
class(r)

# 2
hist(r, probability = TRUE)

# 3
curve(dnorm(x, media, dp), add = TRUE, lwd = 1)

# 4
r %>% 
  data.frame() %>% 
  ggplot(aes(x = r)) +
  geom_histogram(aes(y = ..density..)) +
  stat_function(fun = dnorm, args = list(mean = media, sd = dp))
```


### Exercício Computacional - 3
```{r warning=FALSE}
# 1
df1 <- read.delim("../inputs/conceitos_ml_dataset_1.csv", sep = ",", skip = 20, header = FALSE)
df2 <- read.delim("../inputs/conceitos_ml_dataset_2.csv", sep = ",", skip = 20, header = FALSE)

# 2
# Os dados são, respectivamente, DATA Freq, SA Clear-Write, SA Blank, SA Blank, SA Blank

# 3
hist(df1$V2)
hist(df2$V2)

# 4

leaflet() %>%
  addTiles() %>%
  addMarkers(lng = -45.69582, lat = -22.25679,
             popup = 'ponto 1',
             clusterOptions = markerClusterOptions())

# Informações obtidas dos arquivos .csv
```


### Exercício Computacional - 4
```{r warning=FALSE}
```


### Exercício Computacional - 5
```{r warning=FALSE}
# 1
set.seed(123)
x <- seq(1, 100)
hx <- 3*x + 30
e <- rnorm(100, 0, 15)
y <- hx + e
hxe <- 2.8*x + 32

# 2
plot(x, y, rep = "best")

# 3
hist(y)

# 4
# É relacionada à avaliação das predições do modelo

# 5
mse <- sum((hxe - y)^2)*(1/1000)
mse

# 6
# Sim, visto que o MSE foi baixo e a relação linear entre as váriáveis é alta.

```


### Exercício Computacional - 6
```{r warning=FALSE}
# 1
std_vector = seq(1, 20, length.out = 100)
hx <- 3*x + 30

# 2
mse_v <- rep(0, length(std_vector))
mse <- rep(0, 1000)

for (j in 1:length(std_vector)){
  for (i in 1:1000){
    e <- rnorm(1000, 0, std_vector[j])
    y <- hx + e
    
    hx_e <- 2.8*x + 32
    mse[i] = (1/1000)*sum(((y - hx_e)^2))
  }
  
  mse_v[j] = mean(mse)
}

plot(x = std_vector, y = mse_v, rep = "best")

# 3
# A partir de um certo ponto, sim a acurácia do modelo é afetada
```


### Exercício Computacional - 7
```{r warning=FALSE}
# 1
n_vector = seq(10, 100, 5)
mse_v <- rep(0, length(n_vector))
mse <- rep(0, 1000)

# 2
for (j in 1:length(n_vector)) {
  n = n_vector[j]
  x = seq(1, 100, length.out = n)
  
  hx <- 3*x + 30
  
  for (i in 1:1000){
    std = 0.5
    e <- rnorm(n, 0, std)
    
    y <- hx + e
    hx_e <- 2.8*x + 32
    
    mse[i] = (1/n)*sum(((y - hx_e)^2))
  }
  mse_v[j] = mean(mse)
}

plot(x = n_vector, y = mse_v, rep = "best")

# 3
# A partir de um certo ponto, sim a acurácia do modelo é afetada
```


### Exercício Computacional - 8
```{r warning=FALSE}
# 1
ini <- as.Date("2020-01-01")
fim <- as.Date("2020-06-15")
getSymbols("PETR4.SA", src = "yahoo", from = ini, to = fim)

# 2
petrobras <- na.omit(PETR4.SA) %>% as.data.frame()
candleChart(petrobras)

# 3
hist(petrobras$PETR4.SA.High)

# 4
candleChart(petrobras)
addBBands(1, 20)
```






